{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>group</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Category</th>\n",
       "      <th>issues</th>\n",
       "      <th>identify_cause</th>\n",
       "      <th>initial_theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MOGSC</td>\n",
       "      <td>HSE and Quality</td>\n",
       "      <td>HUCSU &amp; Offshore Maintenance</td>\n",
       "      <td>Revision of CSP25 (Safe House Habitat) by Petr...</td>\n",
       "      <td>- Requirements for Habitat Technicians and Sup...</td>\n",
       "      <td>Capability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MOSVA</td>\n",
       "      <td>Others</td>\n",
       "      <td>Marine &amp; Logistics</td>\n",
       "      <td>Marine Crew Work Permit to get more support an...</td>\n",
       "      <td>Local Authorities implementation</td>\n",
       "      <td>Sabah &amp; Sarawak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>PAC</td>\n",
       "      <td>Capability and Technology</td>\n",
       "      <td>Others (e.g. more than one categories)</td>\n",
       "      <td>Low availability of marine vessels in the mark...</td>\n",
       "      <td>High demand for marine vessels due to High lev...</td>\n",
       "      <td>Contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>PAC</td>\n",
       "      <td>Capability and Technology</td>\n",
       "      <td>Others (e.g. more than one categories)</td>\n",
       "      <td>Shortage of local skilled manpower (10-15 year...</td>\n",
       "      <td>Potentially due to reducing work opportunities...</td>\n",
       "      <td>Capability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>MOGSC</td>\n",
       "      <td>HSE and Quality</td>\n",
       "      <td>HUCSU &amp; Offshore Maintenance</td>\n",
       "      <td>Petronas - SHO (Green Book) required all the t...</td>\n",
       "      <td>- Different standards practices across differe...</td>\n",
       "      <td>HSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  group                      Topic  \\\n",
       "0   1  MOGSC            HSE and Quality   \n",
       "1   1  MOSVA                     Others   \n",
       "2   1    PAC  Capability and Technology   \n",
       "3   2    PAC  Capability and Technology   \n",
       "4   3  MOGSC            HSE and Quality   \n",
       "\n",
       "                                 Category  \\\n",
       "0            HUCSU & Offshore Maintenance   \n",
       "1                      Marine & Logistics   \n",
       "2  Others (e.g. more than one categories)   \n",
       "3  Others (e.g. more than one categories)   \n",
       "4            HUCSU & Offshore Maintenance   \n",
       "\n",
       "                                              issues  \\\n",
       "0  Revision of CSP25 (Safe House Habitat) by Petr...   \n",
       "1  Marine Crew Work Permit to get more support an...   \n",
       "2  Low availability of marine vessels in the mark...   \n",
       "3  Shortage of local skilled manpower (10-15 year...   \n",
       "4  Petronas - SHO (Green Book) required all the t...   \n",
       "\n",
       "                                      identify_cause    initial_theme  \n",
       "0  - Requirements for Habitat Technicians and Sup...       Capability  \n",
       "1                   Local Authorities implementation  Sabah & Sarawak  \n",
       "2  High demand for marine vessels due to High lev...         Contract  \n",
       "3  Potentially due to reducing work opportunities...       Capability  \n",
       "4  - Different standards practices across differe...              HSE  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('text_ORT_topicmodelling.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling (LDA): from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['No', 'group', 'Topic', 'Category', 'issues', 'identify_cause',\n",
       "       'initial_theme'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Capability',\n",
       " 'Contract',\n",
       " 'HSE',\n",
       " 'Integrity',\n",
       " 'Quality',\n",
       " 'Sabah & Sarawak',\n",
       " 'Technology',\n",
       " 'Technology ',\n",
       " 'Technology  '}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.initial_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "['clients', 'company', 'long', 'lack', 'cost', 'manpower', 'personnel', 'approval', 'process', 'work']\n",
      "Topic 1:\n",
      "['vessel', 'financial', 'high', 'project', 'exe', 'petronas', 'bank', 'guarantee', 'bg', 'cost']\n",
      "Topic 2:\n",
      "['immediately', 'inspector', 'work', 'pacs', 'issues', 'local', 'company', 'manpower', 'companies', 'petronas']\n",
      "Topic 3:\n",
      "['vdr', 'project', 'award', 'petronas', 'main', 'payment', 'price', 'contract', 'sub', 'contractor']\n",
      "Topic 4:\n",
      "['permit', 'operations', 'difficulties', 'new', 'contractors', 'work', 'contractor', 'project', 'late', 'payment']\n",
      "Topic 5:\n",
      "['different', 'contractor', 'cost', 'petronas', 'payment', 'lack', 'local', 'contract', 'technology', 'project']\n",
      "Topic 6:\n",
      "['personnel', 'lack', 'time', 'based', 'requirement', 'project', 'vessels', 'cost', 'non', 'contractor']\n",
      "Topic 7:\n",
      "['fund', 'technologies', 'new', 'price', 'tender', 'contractor', 'cost', 'industry', 'high', 'risk']\n",
      "Topic 8:\n",
      "['crew', 'training', 'activities', 'generation', 'ptw', 'high', 'petronas', 'project', 'safety', 'contractor']\n",
      "Topic 9:\n",
      "['expensive', 'sp3d', 'costs', 'procedures', 'cost', 'technology', 'contract', 'petronas', 'new', 'software']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>group</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Category</th>\n",
       "      <th>issues</th>\n",
       "      <th>identify_cause</th>\n",
       "      <th>initial_theme</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>Predicted Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MOGSC</td>\n",
       "      <td>HSE and Quality</td>\n",
       "      <td>HUCSU &amp; Offshore Maintenance</td>\n",
       "      <td>Revision of CSP25 (Safe House Habitat) by Petr...</td>\n",
       "      <td>- Requirements for Habitat Technicians and Sup...</td>\n",
       "      <td>Capability</td>\n",
       "      <td>Revision of CSP25 (Safe House Habitat) by Petr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MOSVA</td>\n",
       "      <td>Others</td>\n",
       "      <td>Marine &amp; Logistics</td>\n",
       "      <td>Marine Crew Work Permit to get more support an...</td>\n",
       "      <td>Local Authorities implementation</td>\n",
       "      <td>Sabah &amp; Sarawak</td>\n",
       "      <td>Marine Crew Work Permit to get more support an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>PAC</td>\n",
       "      <td>Capability and Technology</td>\n",
       "      <td>Others (e.g. more than one categories)</td>\n",
       "      <td>Low availability of marine vessels in the mark...</td>\n",
       "      <td>High demand for marine vessels due to High lev...</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Low availability of marine vessels in the mark...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>PAC</td>\n",
       "      <td>Capability and Technology</td>\n",
       "      <td>Others (e.g. more than one categories)</td>\n",
       "      <td>Shortage of local skilled manpower (10-15 year...</td>\n",
       "      <td>Potentially due to reducing work opportunities...</td>\n",
       "      <td>Capability</td>\n",
       "      <td>Shortage of local skilled manpower (10-15 year...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>MOGSC</td>\n",
       "      <td>HSE and Quality</td>\n",
       "      <td>HUCSU &amp; Offshore Maintenance</td>\n",
       "      <td>Petronas - SHO (Green Book) required all the t...</td>\n",
       "      <td>- Different standards practices across differe...</td>\n",
       "      <td>HSE</td>\n",
       "      <td>Petronas - SHO (Green Book) required all the t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>139</td>\n",
       "      <td>MOGSC</td>\n",
       "      <td>Others</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Milestone is not parallel to cashflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contract</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>141</td>\n",
       "      <td>MOGSC</td>\n",
       "      <td>Others</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Verification of basic engineering is too vague</td>\n",
       "      <td>Petronas GTS do basic engineering wrongly</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Verification of basic engineering is too vague...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>142</td>\n",
       "      <td>MOGSC</td>\n",
       "      <td>Others</td>\n",
       "      <td>Technology &amp; Digitalisation</td>\n",
       "      <td>Preference to Foreign inventions/inventors</td>\n",
       "      <td>Lack of trust to local inventions</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Preference to Foreign inventions/inventors  La...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "      <td>MTEM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bundling/ Unbundling contracting strategy\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contract</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2</td>\n",
       "      <td>MTEM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Industry concern on CPTPP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contract</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      No  group                      Topic  \\\n",
       "0      1  MOGSC            HSE and Quality   \n",
       "1      1  MOSVA                     Others   \n",
       "2      1    PAC  Capability and Technology   \n",
       "3      2    PAC  Capability and Technology   \n",
       "4      3  MOGSC            HSE and Quality   \n",
       "..   ...    ...                        ...   \n",
       "201  139  MOGSC                     Others   \n",
       "202  141  MOGSC                     Others   \n",
       "203  142  MOGSC                     Others   \n",
       "204    1   MTEM                        NaN   \n",
       "205    2   MTEM                        NaN   \n",
       "\n",
       "                                   Category  \\\n",
       "0              HUCSU & Offshore Maintenance   \n",
       "1                        Marine & Logistics   \n",
       "2    Others (e.g. more than one categories)   \n",
       "3    Others (e.g. more than one categories)   \n",
       "4              HUCSU & Offshore Maintenance   \n",
       "..                                      ...   \n",
       "201                             Engineering   \n",
       "202                             Engineering   \n",
       "203             Technology & Digitalisation   \n",
       "204                                     NaN   \n",
       "205                                     NaN   \n",
       "\n",
       "                                                issues  \\\n",
       "0    Revision of CSP25 (Safe House Habitat) by Petr...   \n",
       "1    Marine Crew Work Permit to get more support an...   \n",
       "2    Low availability of marine vessels in the mark...   \n",
       "3    Shortage of local skilled manpower (10-15 year...   \n",
       "4    Petronas - SHO (Green Book) required all the t...   \n",
       "..                                                 ...   \n",
       "201              Milestone is not parallel to cashflow   \n",
       "202     Verification of basic engineering is too vague   \n",
       "203        Preference to Foreign inventions/inventors    \n",
       "204        Bundling/ Unbundling contracting strategy\\n   \n",
       "205                          Industry concern on CPTPP   \n",
       "\n",
       "                                        identify_cause    initial_theme  \\\n",
       "0    - Requirements for Habitat Technicians and Sup...       Capability   \n",
       "1                     Local Authorities implementation  Sabah & Sarawak   \n",
       "2    High demand for marine vessels due to High lev...         Contract   \n",
       "3    Potentially due to reducing work opportunities...       Capability   \n",
       "4    - Different standards practices across differe...              HSE   \n",
       "..                                                 ...              ...   \n",
       "201                                                NaN         Contract   \n",
       "202          Petronas GTS do basic engineering wrongly         Contract   \n",
       "203                 Lack of trust to local inventions       Technology    \n",
       "204                                                NaN         Contract   \n",
       "205                                                NaN         Contract   \n",
       "\n",
       "                                         combined_text  Predicted Topic  \n",
       "0    Revision of CSP25 (Safe House Habitat) by Petr...                0  \n",
       "1    Marine Crew Work Permit to get more support an...                0  \n",
       "2    Low availability of marine vessels in the mark...                8  \n",
       "3    Shortage of local skilled manpower (10-15 year...                2  \n",
       "4    Petronas - SHO (Green Book) required all the t...                5  \n",
       "..                                                 ...              ...  \n",
       "201                                                                   0  \n",
       "202  Verification of basic engineering is too vague...                4  \n",
       "203  Preference to Foreign inventions/inventors  La...                5  \n",
       "204                                                                   0  \n",
       "205                                                                   0  \n",
       "\n",
       "[206 rows x 9 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine text columns for better topic modeling\n",
    "df['combined_text'] = df['issues'] + ' ' + df['identify_cause']\n",
    "\n",
    "# Replace any NaN values with an empty string\n",
    "df['combined_text'] = df['combined_text'].fillna('')\n",
    "\n",
    "# Vectorization (Converting text data to numerical form)\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "X = vectorizer.fit_transform(df['combined_text'])\n",
    "\n",
    "# Fit LDA Model (Assuming we are trying to find 10 topics)\n",
    "lda = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# Get topics\n",
    "def print_topics(model, vectorizer, top_n=10):\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {idx}:\")\n",
    "        print([words[i] for i in topic.argsort()[-top_n:]])\n",
    "\n",
    "# Print the topics\n",
    "print_topics(lda, vectorizer)\n",
    "\n",
    "# Get topic distribution for each document\n",
    "topic_values = lda.transform(X)\n",
    "\n",
    "# Add predicted topics to DataFrame\n",
    "df['Predicted Topic'] = topic_values.argmax(axis=1)\n",
    "\n",
    "# Display the DataFrame with predicted topics\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>group</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Category</th>\n",
       "      <th>issues</th>\n",
       "      <th>identify_cause</th>\n",
       "      <th>initial_theme</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>Predicted Topic</th>\n",
       "      <th>Predicted Subtheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MOGSC</td>\n",
       "      <td>HSE and Quality</td>\n",
       "      <td>HUCSU &amp; Offshore Maintenance</td>\n",
       "      <td>Revision of CSP25 (Safe House Habitat) by Petr...</td>\n",
       "      <td>- Requirements for Habitat Technicians and Sup...</td>\n",
       "      <td>Capability</td>\n",
       "      <td>Revision of CSP25 (Safe House Habitat) by Petr...</td>\n",
       "      <td>0</td>\n",
       "      <td>Manpower Approval and Work Process Challenges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MOSVA</td>\n",
       "      <td>Others</td>\n",
       "      <td>Marine &amp; Logistics</td>\n",
       "      <td>Marine Crew Work Permit to get more support an...</td>\n",
       "      <td>Local Authorities implementation</td>\n",
       "      <td>Sabah &amp; Sarawak</td>\n",
       "      <td>Marine Crew Work Permit to get more support an...</td>\n",
       "      <td>0</td>\n",
       "      <td>Manpower Approval and Work Process Challenges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>PAC</td>\n",
       "      <td>Capability and Technology</td>\n",
       "      <td>Others (e.g. more than one categories)</td>\n",
       "      <td>Low availability of marine vessels in the mark...</td>\n",
       "      <td>High demand for marine vessels due to High lev...</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Low availability of marine vessels in the mark...</td>\n",
       "      <td>8</td>\n",
       "      <td>Crew Training and Safety in High-Activity Proj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>PAC</td>\n",
       "      <td>Capability and Technology</td>\n",
       "      <td>Others (e.g. more than one categories)</td>\n",
       "      <td>Shortage of local skilled manpower (10-15 year...</td>\n",
       "      <td>Potentially due to reducing work opportunities...</td>\n",
       "      <td>Capability</td>\n",
       "      <td>Shortage of local skilled manpower (10-15 year...</td>\n",
       "      <td>2</td>\n",
       "      <td>Local Manpower and Immediate Issues with PACs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>MOGSC</td>\n",
       "      <td>HSE and Quality</td>\n",
       "      <td>HUCSU &amp; Offshore Maintenance</td>\n",
       "      <td>Petronas - SHO (Green Book) required all the t...</td>\n",
       "      <td>- Different standards practices across differe...</td>\n",
       "      <td>HSE</td>\n",
       "      <td>Petronas - SHO (Green Book) required all the t...</td>\n",
       "      <td>5</td>\n",
       "      <td>Contractor Cost and Technology Adoption</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  group                      Topic  \\\n",
       "0   1  MOGSC            HSE and Quality   \n",
       "1   1  MOSVA                     Others   \n",
       "2   1    PAC  Capability and Technology   \n",
       "3   2    PAC  Capability and Technology   \n",
       "4   3  MOGSC            HSE and Quality   \n",
       "\n",
       "                                 Category  \\\n",
       "0            HUCSU & Offshore Maintenance   \n",
       "1                      Marine & Logistics   \n",
       "2  Others (e.g. more than one categories)   \n",
       "3  Others (e.g. more than one categories)   \n",
       "4            HUCSU & Offshore Maintenance   \n",
       "\n",
       "                                              issues  \\\n",
       "0  Revision of CSP25 (Safe House Habitat) by Petr...   \n",
       "1  Marine Crew Work Permit to get more support an...   \n",
       "2  Low availability of marine vessels in the mark...   \n",
       "3  Shortage of local skilled manpower (10-15 year...   \n",
       "4  Petronas - SHO (Green Book) required all the t...   \n",
       "\n",
       "                                      identify_cause    initial_theme  \\\n",
       "0  - Requirements for Habitat Technicians and Sup...       Capability   \n",
       "1                   Local Authorities implementation  Sabah & Sarawak   \n",
       "2  High demand for marine vessels due to High lev...         Contract   \n",
       "3  Potentially due to reducing work opportunities...       Capability   \n",
       "4  - Different standards practices across differe...              HSE   \n",
       "\n",
       "                                       combined_text  Predicted Topic  \\\n",
       "0  Revision of CSP25 (Safe House Habitat) by Petr...                0   \n",
       "1  Marine Crew Work Permit to get more support an...                0   \n",
       "2  Low availability of marine vessels in the mark...                8   \n",
       "3  Shortage of local skilled manpower (10-15 year...                2   \n",
       "4  Petronas - SHO (Green Book) required all the t...                5   \n",
       "\n",
       "                                  Predicted Subtheme  \n",
       "0      Manpower Approval and Work Process Challenges  \n",
       "1      Manpower Approval and Work Process Challenges  \n",
       "2  Crew Training and Safety in High-Activity Proj...  \n",
       "3      Local Manpower and Immediate Issues with PACs  \n",
       "4            Contractor Cost and Technology Adoption  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually map the topics to the actual theme names\n",
    "theme_mapping = {\n",
    "    0: 'Manpower Approval and Work Process Challenges',\n",
    "    1: 'Vessel Costs and Financial Guarantees',\n",
    "    2: 'Local Manpower and Immediate Issues with PACs',\n",
    "    3: 'Project Awards and Contract Payment Issues',\n",
    "    4: 'Work Permits and Operational Delays',\n",
    "    5: 'Contractor Cost and Technology Adoption',\n",
    "    6: 'Personnel Shortage and Vessel Requirements',\n",
    "    7: 'New Technology, High Costs, and Industry Risks',\n",
    "    8: 'Crew Training and Safety in High-Activity Projects',\n",
    "    9: 'High Software Costs and Technology Implementation'\n",
    "}\n",
    "\n",
    "# Map the predicted topics to the corresponding theme names\n",
    "df['Predicted Subtheme'] = df['Predicted Topic'].map(theme_mapping)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>group</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Category</th>\n",
       "      <th>issues</th>\n",
       "      <th>identify_cause</th>\n",
       "      <th>initial_theme</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>Predicted Topic</th>\n",
       "      <th>Predicted Subtheme</th>\n",
       "      <th>Predicted Theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MOGSC</td>\n",
       "      <td>HSE and Quality</td>\n",
       "      <td>HUCSU &amp; Offshore Maintenance</td>\n",
       "      <td>Revision of CSP25 (Safe House Habitat) by Petr...</td>\n",
       "      <td>- Requirements for Habitat Technicians and Sup...</td>\n",
       "      <td>Capability</td>\n",
       "      <td>Revision of CSP25 (Safe House Habitat) by Petr...</td>\n",
       "      <td>0</td>\n",
       "      <td>Manpower Approval and Work Process Challenges</td>\n",
       "      <td>Manpower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MOSVA</td>\n",
       "      <td>Others</td>\n",
       "      <td>Marine &amp; Logistics</td>\n",
       "      <td>Marine Crew Work Permit to get more support an...</td>\n",
       "      <td>Local Authorities implementation</td>\n",
       "      <td>Sabah &amp; Sarawak</td>\n",
       "      <td>Marine Crew Work Permit to get more support an...</td>\n",
       "      <td>0</td>\n",
       "      <td>Manpower Approval and Work Process Challenges</td>\n",
       "      <td>Manpower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>PAC</td>\n",
       "      <td>Capability and Technology</td>\n",
       "      <td>Others (e.g. more than one categories)</td>\n",
       "      <td>Low availability of marine vessels in the mark...</td>\n",
       "      <td>High demand for marine vessels due to High lev...</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Low availability of marine vessels in the mark...</td>\n",
       "      <td>8</td>\n",
       "      <td>Crew Training and Safety in High-Activity Proj...</td>\n",
       "      <td>HSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>PAC</td>\n",
       "      <td>Capability and Technology</td>\n",
       "      <td>Others (e.g. more than one categories)</td>\n",
       "      <td>Shortage of local skilled manpower (10-15 year...</td>\n",
       "      <td>Potentially due to reducing work opportunities...</td>\n",
       "      <td>Capability</td>\n",
       "      <td>Shortage of local skilled manpower (10-15 year...</td>\n",
       "      <td>2</td>\n",
       "      <td>Local Manpower and Immediate Issues with PACs</td>\n",
       "      <td>Manpower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>MOGSC</td>\n",
       "      <td>HSE and Quality</td>\n",
       "      <td>HUCSU &amp; Offshore Maintenance</td>\n",
       "      <td>Petronas - SHO (Green Book) required all the t...</td>\n",
       "      <td>- Different standards practices across differe...</td>\n",
       "      <td>HSE</td>\n",
       "      <td>Petronas - SHO (Green Book) required all the t...</td>\n",
       "      <td>5</td>\n",
       "      <td>Contractor Cost and Technology Adoption</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  group                      Topic  \\\n",
       "0   1  MOGSC            HSE and Quality   \n",
       "1   1  MOSVA                     Others   \n",
       "2   1    PAC  Capability and Technology   \n",
       "3   2    PAC  Capability and Technology   \n",
       "4   3  MOGSC            HSE and Quality   \n",
       "\n",
       "                                 Category  \\\n",
       "0            HUCSU & Offshore Maintenance   \n",
       "1                      Marine & Logistics   \n",
       "2  Others (e.g. more than one categories)   \n",
       "3  Others (e.g. more than one categories)   \n",
       "4            HUCSU & Offshore Maintenance   \n",
       "\n",
       "                                              issues  \\\n",
       "0  Revision of CSP25 (Safe House Habitat) by Petr...   \n",
       "1  Marine Crew Work Permit to get more support an...   \n",
       "2  Low availability of marine vessels in the mark...   \n",
       "3  Shortage of local skilled manpower (10-15 year...   \n",
       "4  Petronas - SHO (Green Book) required all the t...   \n",
       "\n",
       "                                      identify_cause    initial_theme  \\\n",
       "0  - Requirements for Habitat Technicians and Sup...       Capability   \n",
       "1                   Local Authorities implementation  Sabah & Sarawak   \n",
       "2  High demand for marine vessels due to High lev...         Contract   \n",
       "3  Potentially due to reducing work opportunities...       Capability   \n",
       "4  - Different standards practices across differe...              HSE   \n",
       "\n",
       "                                       combined_text  Predicted Topic  \\\n",
       "0  Revision of CSP25 (Safe House Habitat) by Petr...                0   \n",
       "1  Marine Crew Work Permit to get more support an...                0   \n",
       "2  Low availability of marine vessels in the mark...                8   \n",
       "3  Shortage of local skilled manpower (10-15 year...                2   \n",
       "4  Petronas - SHO (Green Book) required all the t...                5   \n",
       "\n",
       "                                  Predicted Subtheme Predicted Theme  \n",
       "0      Manpower Approval and Work Process Challenges        Manpower  \n",
       "1      Manpower Approval and Work Process Challenges        Manpower  \n",
       "2  Crew Training and Safety in High-Activity Proj...             HSE  \n",
       "3      Local Manpower and Immediate Issues with PACs        Manpower  \n",
       "4            Contractor Cost and Technology Adoption      Technology  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually map the topics to the new theme names\n",
    "theme_mapping2 = {\n",
    "    0: 'Manpower',\n",
    "    1: 'Contract',\n",
    "    2: 'Manpower',\n",
    "    3: 'Contract',\n",
    "    4: 'HSE',\n",
    "    5: 'Technology',\n",
    "    6: 'Manpower',\n",
    "    7: 'Technology',\n",
    "    8: 'HSE',\n",
    "    9: 'Technology'\n",
    "}\n",
    "\n",
    "# Map the predicted topics to the corresponding theme names\n",
    "df['Predicted Theme'] = df['Predicted Topic'].map(theme_mapping2)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 0: Manpower Approval and Work Process Challenges\n",
    "\n",
    "Topic 1: Vessel Costs and Financial Guarantees\n",
    "\n",
    "Topic 2: Local Manpower and Immediate Issues with PACs\n",
    "\n",
    "Topic 3: Project Awards and Contract Payment Issues\n",
    "\n",
    "Topic 4: Work Permits and Operational Delays\n",
    "\n",
    "Topic 5: Contractor Cost and Technology Adoption\n",
    "\n",
    "Topic 6: Personnel Shortage and Vessel Requirements\n",
    "\n",
    "Topic 7: New Technology, High Costs, and Industry Risks\n",
    "\n",
    "Topic 8: Crew Training and Safety in High-Activity Projects\n",
    "\n",
    "Topic 9: High Software Costs and Technology Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 0: Manpower\n",
    "\n",
    "Topic 1: Contract\n",
    "\n",
    "Topic 2: Manpower\n",
    "\n",
    "Topic 3: Contract\n",
    "\n",
    "Topic 4: HSE\n",
    "\n",
    "Topic 5: Technology\n",
    "\n",
    "Topic 6: Manpower\n",
    "\n",
    "Topic 7: Technology\n",
    "\n",
    "Topic 8: HSE\n",
    "\n",
    "Topic 9: Technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling (LDA): from gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\ahmadnajmi.ariffin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\ahmadnajmi.ariffin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\ahmadnajmi.ariffin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\ahmadnajmi.ariffin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\ahmadnajmi.ariffin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: click in c:\\users\\ahmadnajmi.ariffin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\ahmadnajmi.ariffin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ahmadnajmi.ariffin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ahmadnajmi.ariffin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\ahmadnajmi.ariffin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ahmadnajmi.ariffin\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ahmadnajmi.ariffin\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ahmadnajmi.ariffin\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\ahmadnajmi.ariffin/nltk_data'\n    - 'c:\\\\Users\\\\ahmadnajmi.ariffin\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\nltk_data'\n    - 'c:\\\\Users\\\\ahmadnajmi.ariffin\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\ahmadnajmi.ariffin\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\ahmadnajmi.ariffin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:/GIT-ONASstg/topic_modelling/nltk_data'\n    - 'C:/GIT-ONASstg/topic_modelling/nltk_data'\n    - 'C:/Users/ahmadnajmi.ariffin/AppData/Roaming/nltk_data'\n    - 'C:/Users/ahmadnajmi.ariffin/AppData/Roaming/nltk_data'\n    - 'C:/Users/ahmadnajmi.ariffin/AppData/Roaming/nltk_data'\n    - 'C:/Users/ahmadnajmi.ariffin/AppData/Roaming/nltk_data'\n    - 'C:/Users/ahmadnajmi.ariffin/AppData/Roaming/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m word_tokenize(text\u001b[38;5;241m.\u001b[39mlower())  \u001b[38;5;66;03m# Convert to lowercase and tokenize\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39misalnum() \u001b[38;5;129;01mand\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words]  \u001b[38;5;66;03m# Remove stop words and non-alphanumeric tokens\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcombined_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ahmadnajmi.ariffin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ahmadnajmi.ariffin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ahmadnajmi.ariffin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\ahmadnajmi.ariffin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ahmadnajmi.ariffin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[50], line 2\u001b[0m, in \u001b[0;36mpreprocess\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(text):\n\u001b[1;32m----> 2\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert to lowercase and tokenize\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39misalnum() \u001b[38;5;129;01mand\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words]\n",
      "File \u001b[1;32mc:\\Users\\ahmadnajmi.ariffin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\ahmadnajmi.ariffin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32mc:\\Users\\ahmadnajmi.ariffin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ahmadnajmi.ariffin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[1;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
      "File \u001b[1;32mc:\\Users\\ahmadnajmi.ariffin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\data.py:582\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    580\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    581\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 582\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\ahmadnajmi.ariffin/nltk_data'\n    - 'c:\\\\Users\\\\ahmadnajmi.ariffin\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\nltk_data'\n    - 'c:\\\\Users\\\\ahmadnajmi.ariffin\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\ahmadnajmi.ariffin\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\ahmadnajmi.ariffin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:/GIT-ONASstg/topic_modelling/nltk_data'\n    - 'C:/GIT-ONASstg/topic_modelling/nltk_data'\n    - 'C:/Users/ahmadnajmi.ariffin/AppData/Roaming/nltk_data'\n    - 'C:/Users/ahmadnajmi.ariffin/AppData/Roaming/nltk_data'\n    - 'C:/Users/ahmadnajmi.ariffin/AppData/Roaming/nltk_data'\n    - 'C:/Users/ahmadnajmi.ariffin/AppData/Roaming/nltk_data'\n    - 'C:/Users/ahmadnajmi.ariffin/AppData/Roaming/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())  # Convert to lowercase and tokenize\n",
    "    return [word for word in tokens if word.isalnum() and word not in stop_words]  # Remove stop words and non-alphanumeric tokens\n",
    "\n",
    "df['processed_text'] = df['combined_text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'processed_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ahmadnajmi.ariffin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'processed_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a dictionary and corpus for Gensim\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dictionary \u001b[38;5;241m=\u001b[39m corpora\u001b[38;5;241m.\u001b[39mDictionary(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprocessed_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      3\u001b[0m corpus \u001b[38;5;241m=\u001b[39m [dictionary\u001b[38;5;241m.\u001b[39mdoc2bow(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_text\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Fit LDA Model (assuming we want 10 topics)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ahmadnajmi.ariffin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\ahmadnajmi.ariffin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'processed_text'"
     ]
    }
   ],
   "source": [
    "# Create a dictionary and corpus for Gensim\n",
    "dictionary = corpora.Dictionary(df['processed_text'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['processed_text']]\n",
    "\n",
    "# Fit LDA Model (assuming we want 10 topics)\n",
    "lda_model = LdaModel(corpus, num_topics=10, id2word=dictionary, passes=15, random_state=42)\n",
    "\n",
    "# Print the topics\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "for idx, topic in topics:\n",
    "    print(f\"Topic {idx}: {topic}\")\n",
    "\n",
    "# Assign the most likely topic to each document\n",
    "def get_document_topics(lda_model, corpus):\n",
    "    topics = []\n",
    "    for doc_bow in corpus:\n",
    "        topic_probs = lda_model.get_document_topics(doc_bow)\n",
    "        top_topic = max(topic_probs, key=lambda x: x[1])[0]  # Get the most probable topic\n",
    "        topics.append(top_topic)\n",
    "    return topics\n",
    "\n",
    "# Add predicted topics to the DataFrame\n",
    "df['Predicted Topic'] = get_document_topics(lda_model, corpus)\n",
    "\n",
    "# Display the DataFrame with predicted topics\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
